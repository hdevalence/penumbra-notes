#!/bin/bash
# Utility script to deploy Penumbra testnet(s) to k8s,
# used as part of CI. At a high level, this script does the following:
#
#  * reads env vars (e.g. from github actions) to set helm values
#  * runs a container with `pd testnet generate` to create genesis
#  * munges the generated data into valid (but internal) peer strings
#  * deploys helm chart to kubernetes cluster, replacing running pods
#  * waits a while, then fetches the public ip addresses
#  * re-munges the generated data into publicly-routable peer strings
#  * re-deploys the helm chart to overwrite the config
#
set -euo pipefail

# The following env vars can be used to override config fars
# for the helm chart. N.B. these env vars are also configured
# in GitHub Actions, so the values below may be out of date.
WORKDIR="${WORKDIR:=$(pwd)/helm/pdcli}"
IMAGE="${IMAGE:-ghcr.io/penumbra-zone/penumbra}"
PENUMBRA_VERSION="${PENUMBRA_VERSION:-main}"
PENUMBRA_UID_GID="${PENUMBRA_UID_GID:-1000\:1000}"
TENDERMINT_VERSION="${TENDERMINT_VERSION:-v0.34.23}"
NVALS="${NVALS:-2}"
NFULLNODES="${NFULLNODES:-1}"
CONTAINERHOME="${CONTAINERHOME:-/root}"
# Default to preview for deployments; less likely to break public testnet.
HELM_RELEASE="${HELM_RELEASE:-penumbra-testnet-preview}"

# Check that the network we're trying to configure has a valid config.
if [[ "$HELM_RELEASE" =~ ^penumbra-testnet$ ]] ; then
    HELM_VARS_FILE="networks/testnet/helm-values-for-${HELM_RELEASE}.yml"
elif [[ "$HELM_RELEASE" =~ ^penumbra-testnet-preview$ ]] ; then
    HELM_VARS_FILE="networks/testnet-preview/helm-values-for-${HELM_RELEASE}.yml"
elif [[ "$HELM_RELEASE" =~ ^penumbra-devnet$ ]] ; then
    HELM_VARS_FILE="networks/devnet/helm-values-for-${HELM_RELEASE}.yml"
else
    >&2 echo "ERROR: helm release name '$HELM_RELEASE' not supported"
    exit 1
fi
if [[ ! -e "$HELM_VARS_FILE" ]]; then
    >&2 echo "ERROR: file not found: '$HELM_VARS_FILE'"
    exit 2
fi

# Use fresh working directory. The dirpath is used within the helm chart,
# to read local files generated by "testnet generate", and push them
# into the cluster config.
test -d "$WORKDIR" && rm -r "$WORKDIR"
mkdir -p "$WORKDIR"

# Remove existing deployment. Intended to omit removal
# of certain durable resources, such as LoadBalancer and ManagedCertificate.
function helm_uninstall() {
    # TODO: We should probably use "helm uninstall $HELM_RELEASE" here.
    # Delete existing replication controllers.
    kubectl delete rc -l app.kubernetes.io/instance="$HELM_RELEASE" --wait=false > /dev/null 2>&1
    # Delete all existing PVCs so that fresh testnet is created.
    kubectl delete pvc -l app.kubernetes.io/instance="$HELM_RELEASE" > /dev/null 2>&1
}
echo "Shutting down existing testnet if necessary..."
helm_uninstall

for i in $(seq "$NVALS"); do
    I="$((i-1))"
    NODEDIR="node${I}"
    mkdir -p "${WORKDIR}/${NODEDIR}"
    # This will be overwritten by pd testnet generate.
    echo '{"identity_key": "penumbravalid1lr73zgd726gpk7rl45hvpg9f7r9wchgg8gpjhx2gqntx4md6gg9sser05u","consensus_key": "9OQ8HOy4YsryEPLbTtPKoKdmmjSqEJhzvS+x0WC8YoM=","name": "","website": "","description": "","enabled": false,"funding_streams": [{"address": "penumbrav2t1wz70yfqlgzfgwml5ne04vhnhahg8axmaupuv7x0gpuzesfhhz63y52cqffv93k7qvuuq6yqtgcj0z267v59qxpjuvc0hvfaynaaemgmqzyj38xhj8yjx7vcftnyq9q28exjrdj","rate_bps": 100}],"sequence_number": 0,"governance_key": "penumbragovern1lr73zgd726gpk7rl45hvpg9f7r9wchgg8gpjhx2gqntx4md6gg9sthagp6"}' > "${WORKDIR}/${NODEDIR}/val.json"
done

find "$WORKDIR" -name "val.json" -exec cat {} + | jq -s > "${WORKDIR}/vals.json"

# Get CLI program for running containers. Prefers podman if available,
# defaults to docker otherwise. Helpful for running script on workstations.
function get_container_cli() {
    if hash podman > /dev/null 2>&1 ; then
        echo "podman"
    else
        echo "docker"
    fi
}

# For the weekly testnets, we pass `--preserve-chain-id` when generating
# the config. For testnet-preview, we don't want that option: we want
# a unique chain id for every deploy.
if [[ "$HELM_RELEASE" =~ ^penumbra-testnet$ ]] ; then
    preserve_chain_opt="--preserve-chain-id"
else
    preserve_chain_opt=""
fi
echo "Generating new testnet files..."
container_cli="$(get_container_cli)"
# Silence shellcheck warning on 'preserve_chain_opt' being an empty string.
# shellcheck disable=SC2086
"$container_cli" run --user 0:0 \
    --pull always \
    -v "${WORKDIR}:${CONTAINERHOME}" --rm \
    --entrypoint pd \
    "${IMAGE}:${PENUMBRA_VERSION}" \
    testnet generate \
    $preserve_chain_opt \
    --validators-input-file "${CONTAINERHOME}/vals.json" > /dev/null

PERSISTENT_PEERS=""
for i in $(seq "$NVALS"); do
    I=$((i-1))
    NODE_ID=$(jq -r '.priv_key.value' "${WORKDIR}/.penumbra/testnet_data/node${I}/tendermint/config/node_key.json" | base64 --decode | tail -c 32 | sha256sum  | cut -c -40)
    SVC_NAME="${HELM_RELEASE}-p2p-val-${I}"
    for j in $(seq "$NVALS")
    do
      J=$((j-1))
      if [ "$I" -ne "$J" ]; then
        PVAR=PERSISTENT_PEERS_$J
        if [ -z "${PVAR}" ]; then
          declare PERSISTENT_PEERS_$J="${NODE_ID}@${SVC_NAME}:26656"
        else
          declare PERSISTENT_PEERS_$J="${PERSISTENT_PEERS},${NODE_ID}@${SVC_NAME}:26656"
        fi
      fi
    done
    if [ -z "$PERSISTENT_PEERS" ]; then
      PERSISTENT_PEERS="${NODE_ID}@${SVC_NAME}:26656"
    else
      PERSISTENT_PEERS="${PERSISTENT_PEERS},${NODE_ID}@${SVC_NAME}:26656"
    fi

    # Clear out external address and persistent peers. Will peer after services are bootstrapped.
    echo > "${WORKDIR}/external_address_val_${I}.txt"
    echo > "${WORKDIR}/persistent_peers_${I}.txt"
done

for i in $(seq "$NFULLNODES"); do
    I=$((i-1))
    # Clear out external address. Will peer after services are bootstrapped.
    echo > "${WORKDIR}/external_address_fn_${I}.txt"
done

# Clear out persistent peers. Will peer after services are bootstrapped.
echo > "${WORKDIR}/persistent_peers.txt"

# Apply the Helm configuration to the cluster. Will overwrite resources
# as necessary. Will *not* replace certain durable resources like
# the ManagedCertificate, which is annotated with helm.sh/resource-policy=keep.
function helm_install() {
    helm upgrade --install "$HELM_RELEASE" ./helm \
        --set "numValidators=$NVALS" \
        --set "numFullNodes=$NFULLNODES" \
        --set "penumbra.image=$IMAGE" \
        --set "penumbra.version=$PENUMBRA_VERSION" \
        --set "penumbra.uidGid=$PENUMBRA_UID_GID" \
        --set "tendermint.version=$TENDERMINT_VERSION" \
        --values "$HELM_VARS_FILE"
}
echo "Performining initial deploy of network, with private IPs..."
# Will deploy nodes, but will not be able to peer. Need to get IPs of services, then can peer
helm_install

while true; do
  echo "Waiting for load balancer external IPs to be provisioned..."
  mapfile -t STATUSES < <(kubectl get svc -l app.kubernetes.io/instance="$HELM_RELEASE" --no-headers | grep p2p | awk '{print $4}')
  FOUND_PENDING=false
  for STATUS in "${STATUSES[@]}"; do
    if [[ "$STATUS" == "<pending>" ]]; then
      sleep 5
      FOUND_PENDING=true
      break
    fi
  done
  if [[ "$FOUND_PENDING" == "false" ]]; then
    break
  fi
done

function wait_for_pods_to_be_running() {
    echo "Waiting for pods to be running..."
    kubectl get pods -l app.kubernetes.io/instance="$HELM_RELEASE" -o name \
        | xargs -r kubectl wait --for=condition=ready --timeout=5m
}

wait_for_pods_to_be_running

PPE=""

echo "Collecting config values for each node..."
for i in $(seq "$NVALS"); do
  I=$((i-1))
  echo "Getting public peer string for validator $I"
  NODE_ID="$(kubectl exec "$(kubectl get pods -l app.kubernetes.io/instance="$HELM_RELEASE" -o name | grep "penumbra.*val-${I}")" -c tm -- tendermint --home=/home/.tendermint show-node-id | tr -d '\r')"
  IP="$(kubectl get svc "${HELM_RELEASE}-p2p-val-${I}" -o json | jq -r .status.loadBalancer.ingress[0].ip | tr -d '\r')"
  if [ -z "$PPE" ]; then
    PPE="${NODE_ID}@${IP}:26656"
  else
    PPE="${PPE},${NODE_ID}@${IP}:26656"
  fi
  # Now write private peering connection to other nodes for validator, and external service address to advertise.
  PVAR=PERSISTENT_PEERS_$I
  echo "${!PVAR}" > "${WORKDIR}/persistent_peers_${I}.txt"
  echo "${IP}:26656" > "${WORKDIR}/external_address_val_${I}.txt"
done

for i in $(seq "$NFULLNODES"); do
  I=$((i-1))
  echo "Getting public peer string for fullnode $I"
  NODE_ID="$(kubectl exec "$(kubectl get pods -l app.kubernetes.io/instance="$HELM_RELEASE" -o name | grep "penumbra.*-fn-${I}")" -c tm -- tendermint --home=/home/.tendermint show-node-id | tr -d '\r')"
  IP="$(kubectl get svc "${HELM_RELEASE}-p2p-fn-${I}" -o json | jq -r .status.loadBalancer.ingress[0].ip | tr -d '\r')"
  PPE="${PPE},${NODE_ID}@${IP}:26656"
  # Now write external service address to advertise.
  echo "${IP}:26656" > "${WORKDIR}/external_address_fn_${I}.txt"
done

# Now write private peering connection to other nodes for full nodes.
echo "$PERSISTENT_PEERS" > "${WORKDIR}/persistent_peers.txt"


echo "Applying fresh values so that nodes can peer and advertise external addresses."
# First, remove the old resources.
helm_uninstall
helm_install
wait_for_pods_to_be_running

# Display persistent peer string at end of run, to facilitate client connections via copy/paste.
echo "persistent_peers = \"$PPE\""

# Clean up local secrets, to avoid contaminating deploy config
# for different environment.
test -d "$WORKDIR" && rm -r "$WORKDIR"
